{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application: Sentiment Analysis\\\n",
    "Dataset: Download the dataset from Sentiment Analysis Dataset (kaggle.com)\\\n",
    "Task:\\\n",
    "▪ Explain the pipeline for developing sentiment analysis task.\\\n",
    "▪ Perform cleaning and preprocessing of text.\\\n",
    "▪ Generate representations using:\\\n",
    "• Bag of Words\\\n",
    "• TF-IDF\\\n",
    "• Continuous Bag of Words\\\n",
    "• Skip gram\\\n",
    "• Word2Vec.\\\n",
    "▪ Classify the data using appropriate machine learning techniques to generate labels.\\\n",
    "▪ Analyze the labels and explain the impact of embedding techniques in misclassification.\\\n",
    "▪ Discuss the limitations of each embedding technique and explain the techniques that rectify it.\\\n",
    "Input:\\\n",
    "What is not to like about this product.\\\n",
    "Not bad.\\\n",
    "Not an issue.\\\n",
    "Not buggy.\\\n",
    "Not happy.\\\n",
    "Not user-friendly.\\\n",
    "Not good.\\\n",
    "Is it any good?\\\n",
    "I do not dislike horror movies.\\\n",
    "Disliking horror movies is not uncommon.\\\n",
    "Sometimes I really hate the show.\\\n",
    "I love having to wait two months for the next series to come out!\\\n",
    "The final episode was surprising with a terrible twist at the end.\\\n",
    "The film was easy to watch but I would not recommend it to my friends.\\\n",
    "I LOL’d at the end of the cake scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Gathering\n",
    "2. Data Preprocessing\n",
    "    - remove irrelavant chars\n",
    "    - remove stop words\n",
    "    - lemmatization, stemming\n",
    "3. Feature Extraction\n",
    "4. Model\n",
    "5. Training\n",
    "6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import string as st\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ex2-sent_an.csv\",\n",
    "                   encoding='unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         selected_text sentiment\n",
       "0  I`d have responded, if I were going   neutral\n",
       "1                             Sooo SAD  negative\n",
       "2                          bullying me  negative\n",
       "3                       leave me alone  negative\n",
       "4                        Sons of ****,  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['selected_text','sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment\n",
       "0  I`d have responded, if I were going   neutral\n",
       "1                             Sooo SAD  negative\n",
       "2                          bullying me  negative\n",
       "3                       leave me alone  negative\n",
       "4                        Sons of ****,  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={\"selected_text\":\"text\"},inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27480 entries, 0 to 27480\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       27480 non-null  object\n",
      " 1   sentiment  27480 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 644.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    removed_text = \"\"\n",
    "    for char in str(text):\n",
    "        if char not in st.punctuation:\n",
    "            removed_text+=char\n",
    "    return removed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['removed_punc'] = data['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>removed_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                        removed_punc  \n",
       "0  Id have responded if I were going  \n",
       "1                           Sooo SAD  \n",
       "2                        bullying me  \n",
       "3                     leave me alone  \n",
       "4                           Sons of   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens(text):\n",
    "    text = str(text).lower()\n",
    "    tokens = []\n",
    "    tokens = re.split(\"\\s+\",text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tokens'] = data['removed_punc'].apply(convert_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>removed_punc</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>[bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of</td>\n",
       "      <td>[sons, of, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                        removed_punc  \\\n",
       "0  Id have responded if I were going   \n",
       "1                           Sooo SAD   \n",
       "2                        bullying me   \n",
       "3                     leave me alone   \n",
       "4                           Sons of    \n",
       "\n",
       "                                      Tokens  \n",
       "0  [id, have, responded, if, i, were, going]  \n",
       "1                                [sooo, sad]  \n",
       "2                             [bullying, me]  \n",
       "3                         [leave, me, alone]  \n",
       "4                               [sons, of, ]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['removed_stopwords_tokens'] = data['Tokens'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>removed_punc</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>removed_stopwords_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>[bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>[leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of</td>\n",
       "      <td>[sons, of, ]</td>\n",
       "      <td>[sons, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                        removed_punc  \\\n",
       "0  Id have responded if I were going   \n",
       "1                           Sooo SAD   \n",
       "2                        bullying me   \n",
       "3                     leave me alone   \n",
       "4                           Sons of    \n",
       "\n",
       "                                      Tokens removed_stopwords_tokens  \n",
       "0  [id, have, responded, if, i, were, going]   [id, responded, going]  \n",
       "1                                [sooo, sad]              [sooo, sad]  \n",
       "2                             [bullying, me]               [bullying]  \n",
       "3                         [leave, me, alone]           [leave, alone]  \n",
       "4                               [sons, of, ]                 [sons, ]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(tok) for tok in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stemming_tokens'] = data['removed_stopwords_tokens'].apply(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>removed_punc</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>removed_stopwords_tokens</th>\n",
       "      <th>stemming_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>[bullying]</td>\n",
       "      <td>[bulli]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>[leave, alone]</td>\n",
       "      <td>[leav, alon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of</td>\n",
       "      <td>[sons, of, ]</td>\n",
       "      <td>[sons, ]</td>\n",
       "      <td>[son, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                        removed_punc  \\\n",
       "0  Id have responded if I were going   \n",
       "1                           Sooo SAD   \n",
       "2                        bullying me   \n",
       "3                     leave me alone   \n",
       "4                           Sons of    \n",
       "\n",
       "                                      Tokens removed_stopwords_tokens  \\\n",
       "0  [id, have, responded, if, i, were, going]   [id, responded, going]   \n",
       "1                                [sooo, sad]              [sooo, sad]   \n",
       "2                             [bullying, me]               [bullying]   \n",
       "3                         [leave, me, alone]           [leave, alone]   \n",
       "4                               [sons, of, ]                 [sons, ]   \n",
       "\n",
       "     stemming_tokens  \n",
       "0  [id, respond, go]  \n",
       "1        [sooo, sad]  \n",
       "2            [bulli]  \n",
       "3       [leav, alon]  \n",
       "4            [son, ]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tokens):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    tokens = [wordnet.lemmatize(tok) for tok in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemma_tokens'] = data['removed_stopwords_tokens'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>removed_punc</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>removed_stopwords_tokens</th>\n",
       "      <th>stemming_tokens</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Id have responded if I were going</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>[bullying]</td>\n",
       "      <td>[bulli]</td>\n",
       "      <td>[bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>[leave, alone]</td>\n",
       "      <td>[leav, alon]</td>\n",
       "      <td>[leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of</td>\n",
       "      <td>[sons, of, ]</td>\n",
       "      <td>[sons, ]</td>\n",
       "      <td>[son, ]</td>\n",
       "      <td>[son, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                        removed_punc  \\\n",
       "0  Id have responded if I were going   \n",
       "1                           Sooo SAD   \n",
       "2                        bullying me   \n",
       "3                     leave me alone   \n",
       "4                           Sons of    \n",
       "\n",
       "                                      Tokens removed_stopwords_tokens  \\\n",
       "0  [id, have, responded, if, i, were, going]   [id, responded, going]   \n",
       "1                                [sooo, sad]              [sooo, sad]   \n",
       "2                             [bullying, me]               [bullying]   \n",
       "3                         [leave, me, alone]           [leave, alone]   \n",
       "4                               [sons, of, ]                 [sons, ]   \n",
       "\n",
       "     stemming_tokens            lemma_tokens  \n",
       "0  [id, respond, go]  [id, responded, going]  \n",
       "1        [sooo, sad]             [sooo, sad]  \n",
       "2            [bulli]              [bullying]  \n",
       "3       [leav, alon]          [leave, alone]  \n",
       "4            [son, ]                 [son, ]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentence(tokens):\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_processed_text'] = data['lemma_tokens'].apply(return_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pre_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>id responded going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>sooo sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bullying me</td>\n",
       "      <td>bullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave me alone</td>\n",
       "      <td>leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>son</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text  pre_processed_text\n",
       "0  I`d have responded, if I were going  id responded going\n",
       "1                             Sooo SAD            sooo sad\n",
       "2                          bullying me            bullying\n",
       "3                       leave me alone         leave alone\n",
       "4                        Sons of ****,                son "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['text','pre_processed_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(data['pre_processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 17424)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impact on BoW\n",
    "- BoW may struggle with capturing semantic meaning and context, leading to misclassification. \n",
    "- It treats each word independently, ignoring word relationships.\n",
    "- OOV Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['pre_processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 17424)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact on TF-IDF\n",
    "- While TF-IDF addresses some BoW limitations by giving more weight to important words, it still doesn't capture word relationships and semantics well.\n",
    "- OOV Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Word2Vec(data['pre_processed_text'],\n",
    "                vector_size=100,\n",
    "                window = 5,\n",
    "                min_count= 2,\n",
    "                sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = cbow.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'e', 'o', 'a', 't', 'n', 'i', 'r', 'l', 's']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(model, sentence):\n",
    "    words = [word for word in sentence if word in vocab]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model.wv[words], axis=0)\n",
    "    return np.zeros((100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_array = []\n",
    "\n",
    "for sentence in data['pre_processed_text'].values.tolist():\n",
    "    cbow_array.append(get_mean_vector(cbow, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_array = np.array(cbow_array)\n",
    "cbow_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = Word2Vec(data['pre_processed_text'],\n",
    "              vector_size = 100,\n",
    "              window = 5,\n",
    "              min_count = 2, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sg.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(model, sentence):\n",
    "    words = [word for word in sentence if word in vocab]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model.wv[words], axis=0)\n",
    "    return np.zeros((100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_array = []\n",
    "for sentence in data['pre_processed_text'].values.tolist():\n",
    "    sg_array.append(get_mean_vector(sg, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_array = np.array(sg_array)\n",
    "sg_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "data['sentiment'] = lb.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow, x_test_bow, y_train_bow, y_test_bow = train_test_split(count_matrix, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_array, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_cbow, x_test_cbow, y_train_cbow, y_test_cbow = train_test_split(cbow_array, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_skg, x_test_skg, y_train_skg, y_test_skg = train_test_split(sg_array, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Shapes:\n",
      "x_train_bow shape: (21984, 17424)\n",
      "x_test_bow shape: (5496, 17424)\n",
      "y_train_bow shape: (21984,)\n",
      "y_test_bow shape: (5496,)\n",
      "=======================\n",
      "\n",
      "TF-IDF Shapes:\n",
      "x_train_tfidf shape: (21984, 17424)\n",
      "x_test_tfidf shape: (5496, 17424)\n",
      "y_train_tfidf shape: (21984,)\n",
      "y_test_tfidf shape: (5496,)\n",
      "=========================\n",
      "\n",
      "Continuous Bag of Words (CBOW) Shapes:\n",
      "x_train_cbow shape: (21984, 100)\n",
      "x_test_cbow shape: (5496, 100)\n",
      "y_train_cbow shape: (21984,)\n",
      "y_test_cbow shape: (5496,)\n",
      "========================\n",
      "\n",
      "Skip-Gram Shapes:\n",
      "x_train_skg shape: (21984, 100)\n",
      "x_test_skg shape: (5496, 100)\n",
      "y_train_skg shape: (21984,)\n",
      "y_test_skg shape: (5496,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Shapes:\")\n",
    "print(\"x_train_bow shape:\", x_train_bow.shape)\n",
    "print(\"x_test_bow shape:\", x_test_bow.shape)\n",
    "print(\"y_train_bow shape:\", y_train_bow.shape)\n",
    "print(\"y_test_bow shape:\", y_test_bow.shape)\n",
    "print(\"=======================\")\n",
    "print(\"\\nTF-IDF Shapes:\")\n",
    "print(\"x_train_tfidf shape:\", x_train_tfidf.shape)\n",
    "print(\"x_test_tfidf shape:\", x_test_tfidf.shape)\n",
    "print(\"y_train_tfidf shape:\", y_train_tfidf.shape)\n",
    "print(\"y_test_tfidf shape:\", y_test_tfidf.shape)\n",
    "print(\"=========================\")\n",
    "print(\"\\nContinuous Bag of Words (CBOW) Shapes:\")\n",
    "print(\"x_train_cbow shape:\", x_train_cbow.shape)\n",
    "print(\"x_test_cbow shape:\", x_test_cbow.shape)\n",
    "print(\"y_train_cbow shape:\", y_train_cbow.shape)\n",
    "print(\"y_test_cbow shape:\", y_test_cbow.shape)\n",
    "print(\"========================\")\n",
    "print(\"\\nSkip-Gram Shapes:\")\n",
    "print(\"x_train_skg shape:\", x_train_skg.shape)\n",
    "print(\"x_test_skg shape:\", x_test_skg.shape)\n",
    "print(\"y_train_skg shape:\", y_train_skg.shape)\n",
    "print(\"y_test_skg shape:\", y_test_skg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_decision_tree(x_train, x_test, y_train, y_test, representation):\n",
    "    \n",
    "    dtclassifier = DecisionTreeClassifier(random_state=9,max_depth=5)\n",
    "    dtclassifier.fit(x_train, y_train)\n",
    "    y_pred = dtclassifier.predict(x_test)\n",
    "\n",
    "    print(f\"\\nMetrics for {representation}:\")\n",
    "    print(f\"Model Score: {dtclassifier.score(x_train,y_train)}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_navie_bayes(x_train, x_test, y_train, y_test, representation):\n",
    "    \n",
    "    nbclassifier = MultinomialNB()\n",
    "    nbclassifier.fit(x_train, y_train)\n",
    "    y_pred = nbclassifier.predict(x_test)\n",
    "\n",
    "    print(f\"\\nMetrics for {representation}:\")\n",
    "    print(f\"Model Score: {nbclassifier.score(x_train,y_train)}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    return nbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for BoW:\n",
      "Model Score: 0.4932678311499272\n",
      "Accuracy: 0.4798034934497817\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.00      0.00      1548\n",
      "           1       0.43      0.94      0.59      2182\n",
      "           2       0.79      0.33      0.46      1766\n",
      "\n",
      "    accuracy                           0.48      5496\n",
      "   macro avg       0.61      0.42      0.35      5496\n",
      "weighted avg       0.59      0.48      0.39      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_decision_tree(x_train_bow, x_test_bow, y_train_bow, y_test_bow, \"BoW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for TF-IDF:\n",
      "Model Score: 0.5020469432314411\n",
      "Accuracy: 0.4885371179039301\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1548\n",
      "           1       0.44      0.99      0.61      2182\n",
      "           2       0.91      0.30      0.45      1766\n",
      "\n",
      "    accuracy                           0.49      5496\n",
      "   macro avg       0.78      0.43      0.35      5496\n",
      "weighted avg       0.75      0.49      0.39      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_decision_tree(x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for CBOW:\n",
      "Model Score: 0.6477893013100436\n",
      "Accuracy: 0.6299126637554585\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52      1548\n",
      "           1       0.67      0.79      0.72      2182\n",
      "           2       0.65      0.55      0.60      1766\n",
      "\n",
      "    accuracy                           0.63      5496\n",
      "   macro avg       0.62      0.61      0.61      5496\n",
      "weighted avg       0.63      0.63      0.62      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_decision_tree(x_train_cbow, x_test_cbow, y_train_cbow, y_test_cbow, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Skip-Gram:\n",
      "Model Score: 0.6309133915574964\n",
      "Accuracy: 0.61608442503639\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.39      0.49      1548\n",
      "           1       0.67      0.70      0.69      2182\n",
      "           2       0.55      0.71      0.62      1766\n",
      "\n",
      "    accuracy                           0.62      5496\n",
      "   macro avg       0.63      0.60      0.60      5496\n",
      "weighted avg       0.63      0.62      0.61      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_decision_tree(x_train_skg, x_test_skg, y_train_skg, y_test_skg, \"Skip-Gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for BoW:\n",
      "Model Score: 0.8563045851528385\n",
      "Accuracy: 0.7530931586608443\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69      1548\n",
      "           1       0.71      0.81      0.76      2182\n",
      "           2       0.78      0.80      0.79      1766\n",
      "\n",
      "    accuracy                           0.75      5496\n",
      "   macro avg       0.76      0.74      0.75      5496\n",
      "weighted avg       0.76      0.75      0.75      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc_1 = train_and_evaluate_navie_bayes(x_train_bow, x_test_bow, y_train_bow, y_test_bow, \"BoW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for Tf-IDF:\n",
      "Model Score: 0.8605349344978166\n",
      "Accuracy: 0.774745269286754\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.59      0.70      1548\n",
      "           1       0.71      0.89      0.79      2182\n",
      "           2       0.82      0.79      0.81      1766\n",
      "\n",
      "    accuracy                           0.77      5496\n",
      "   macro avg       0.80      0.76      0.77      5496\n",
      "weighted avg       0.79      0.77      0.77      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbc_2 = train_and_evaluate_navie_bayes(x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf, \"Tf-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"What is not to like about this product.\",\n",
    "    \"Not bad.\",\n",
    "    \"Not an issue.\",\n",
    "    \"Not buggy.\",\n",
    "    \"Not happy.\",\n",
    "    \"Not user-friendly.\",\n",
    "    \"Not good.\",\n",
    "    \"Is it any good?\",\n",
    "    \"I do not dislike horror movies.\",\n",
    "    \"Disliking horror movies is not uncommon.\",\n",
    "    \"Sometimes I really hate the show.\",\n",
    "    \"I love having to wait two months for the next series to come out!\",\n",
    "    \"The final episode was surprising with a terrible twist at the end.\",\n",
    "    \"The film was easy to watch but I would not recommend it to my friends.\",\n",
    "    \"I LOL’d at the end of the cake scene\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocess(text):\n",
    "    text = remove_punctuation(text)\n",
    "    tokens = convert_tokens(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatization(tokens)\n",
    "    return return_sentence(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is not to like about this product.: Positive\n",
      "Not bad.: Negative\n",
      "Not an issue.: Neutral\n",
      "Not buggy.: Neutral\n",
      "Not happy.: Positive\n",
      "Not user-friendly.: Neutral\n",
      "Not good.: Positive\n",
      "Is it any good?: Positive\n",
      "I do not dislike horror movies.: Negative\n",
      "Disliking horror movies is not uncommon.: Negative\n",
      "Sometimes I really hate the show.: Neutral\n",
      "I love having to wait two months for the next series to come out!: Neutral\n",
      "The final episode was surprising with a terrible twist at the end.: Neutral\n",
      "The film was easy to watch but I would not recommend it to my friends.: Neutral\n",
      "I LOL’d at the end of the cake scene: Neutral\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    preprocessed_text = simple_preprocess(text)\n",
    "    transformed_text = tfidf.transform([preprocessed_text]).toarray()\n",
    "    prediction = nbc_2.predict(transformed_text)[0]\n",
    "    \n",
    "    if prediction == 0:\n",
    "        print(f\"{text}: Negative\")\n",
    "    elif prediction == 1:\n",
    "        print(f\"{text}: Neutral\")\n",
    "    elif prediction == 2:\n",
    "        print(f\"{text}: Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
